<!DOCTYPE html>
<html>

<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-XB3PR2Y1TQ"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-XB3PR2Y1TQ');
    </script>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <title>Mind3D</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/css/bootstrap.min.css">
    <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,500,600' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="/assets/css/Highlight-Clean.css">
    <link rel="stylesheet" href="/assets/css/styles.css">

    <link rel="apple-touch-icon" sizes="180x180" href="/assets/icon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/assets/icon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/assets/icon/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">

    <meta property="og:site_name" content="DreamFusion: Text-to-3D using 2D Diffusion" />
    <meta property="og:type" content="video.other" />
    <meta property="og:title" content="DreamFusion: Text-to-3D using 2D Diffusion" />
    <meta property="og:description" content="DreamFusion: Text-to-3D using 2D Diffusion, 2022." />
    <meta property="og:url" content="https://dreamfusion3d.github.io/" />
    <meta property="og:image" content="https://dreamfusion3d.github.io/assets/images/dreamfusion_samples.png" />

    <meta property="article:publisher" content="https://dreamfusion3d.github.io/" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="DreamFusion: Text-to-3D using 2D Diffusion" />
    <meta name="twitter:description" content="We combine neural rendering with a multi-modal text-to-2D image diffusion generative model to synthesize diverse 3D objects from text." />
    <meta name="twitter:url" content="https://dreamfusion3d.github.io/" />
    <meta name="twitter:image" content="https://dreamfusion3d.github.io/assets/images/dreamfusion_samples.png" />
    <!-- <meta name="twitter:site" content="" /> -->

    <script src="assets/js/video_comparison.js"></script>
    <script type="module" src="https://unpkg.com/@google/model-viewer@2.0.1/dist/model-viewer.min.js"></script>
</head>

<body>

    <div class="highlight-clean" style="padding-bottom: 10px;">
        <div class="container" style="max-width: 768px;">
            <h2 class="text-center">Decoding the 3D Vision: 3D Object Reconstructions
            from fMRI Encodings of 2D Visual Stimuli</h2>
        </div>
        <!-- <div class="container" style="max-width: 768px;">
            <div class="row authors">
                <div class="col-sm">
                    <h5 class="text-center">Anonymous Author</h5>
                    <h6 class="text-center">Affiliation</h6>
                </div>
            </div>    
        </div> -->

    </div>
    <hr class="divider" />

    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h3>Abstract</h3>
                <p>
                    When observing objects, the human brain inherently possesses high-level information related to 3D geometry and
                    semantics. However, there have been no significant efforts to extract 3D geometric structures from brain signals to understand and
                    quantify the mechanisms of 3D visual perception. Therefore, we introduced Mind3D, which uses UMAP projection to extract
                    advanced information from fMRI and uses a two-stage diffusion pipeline to gradually refine this information into 3D objects.
                    Mind3D achieves high-quality 3D reconstruction from fMRI, highlighting the presence of high-level geometric information
                    in human object perception. 
                </p>
            </div>
        </div>
    </div>

    <div class="container" style="max-width: 768px;">
        <div style="text-align: center;">
            <img src="assets/image/pipeline-1.png" style="width: 80%;">
        </div>
    <div style="display: flex; justify-content: center; align-items: center;">
        <img src="assets/image/pipeline1-1.png" style="width: 58%; max-width: 58%; flex-grow: 0; flex-shrink: 1;">
        <img src="assets/image/pipeline2-1.png" style="width: 42%; max-width: 42%; flex-grow: 0; flex-shrink: 1;">
    </div>
    </div>


    <hr class="divider" />
    
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h3>3D Reconstruction</h3>
                <p>
                    Mind3D achieves high-quality 3D reconstruction from fMRI, highlighting the presence of high-level
                    geometric information in human object perception. 
                </p>
            </div>
        </div>
    </div>
<div class="container" style="max-width: 768px;">

<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
            <div class="half" style="width: 12%; text-align: center; margin-right: 1%;">
                <p>images</p>
            </div>
    <div class="half" style="width: 36%; text-align: center;; margin-right: 2%;">
            <p>3D objects from fMRI</p>
        </div>
        <div class="half" style="width: 12%; text-align: center; margin-left: 1%;">
            <p>images</p>
        </div>
        <div class="half" style="width: 36%; text-align: center;">
            <p>3D objects from fMRI</p>
        </div>
    <img src="assets/video/images_gt/209.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/209.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/323.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/323.mp4" type="video/mp4">
        </source>
    </video>
</div>



<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/79.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/79.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/39.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/39.mp4" type="video/mp4">
        </source>
    </video>
</div>




<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/9.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/9.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/222.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/222.mp4" type="video/mp4">
        </source>
    </video>
</div>




<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/147.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/147.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/177.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/177.mp4" type="video/mp4">
        </source>
    </video>
</div>

<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/340.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/340.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/77.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/77.mp4" type="video/mp4">
        </source>
    </video>
</div>


    <hr class="divider" />
<div class="container" style="max-width: 768px;">
    <div class="row">
        <div class="col-md-12">
            <h3>Results</h3>
            <!-- <p>
            By analyzing the 3D generation of fMRI, we observed that the interaction between the left and
            right hemispheres of the brain can improve visual quality. 
            We also found a joint contribution between the visual brain
            region
            and the medial temporal lobe (MTL) brain region in forming a comprehensive understanding of the observed object. V1
            brain
            regions excel in capturing features and silhouettes, while V2, V3, and V4 regions complement this by emphasizing texture
            and
            color based on V1. These findings shed light on how the human brain processes high-level geometry alongside low-level
            textures, providing valuable insights into the human visual perception mechanisms.
            </p> -->
            <h4>Left and right hemispheres collaborate to improve the visual quality</h4>
            <p>Experiments conducted on the left and right brain hemispheres separately for feature extraction and 3D decoding showed
            no significant difference in performance across several 3D processing methods (Inception, CLIP, EfficientNet, and Swav).
            However, combining both hemispheres led to improved reconstruction and 3D processing performance. While both hemispheres
            demonstrated similar abilities in object feature perception across various evaluation metrics, their performance varied
            on individual objects. Differences were also noted in the reconstruction of objects when comparing the left and right
            hemispheres, with their combined effort resulting in better quality in 3D scene generation.</p>


            <img src="assets/image/images1-1.png" style="width: 100%;">
<!--
            <p>
                 <strong>a</strong> We experimented on the left and right hemispheres separately for feature extraction and 3D
                decoding.
                <strong>b</strong> There is no clear difference in the overall performance in the left and right hemispheres in 3D
                Inception, 3D
                CLIP, 3D EfficientNet, and 3D Swav. <strong>c-d</strong> The combination of both left and right hemispheres could
                reconstruct
                the object with better 3D Inception, 3D CLIP, 3D EfficientNet, and 3D Swav performance. <strong>e-f</strong> Left
                and right
                hemispheres show a close object feature perception ability in all evaluation metrics in every quantile. Boxen plot
                shows
                5&#37;, 15&#37;, 25&#37;, 50&#37;, 75&#37;, 85&#37;, and 95&#37; percentile. <strong>g-j</strong> Although the left
                and right hemispheres achieve a
                close overall reconstruction performance, their performance is quite different among each specific object.
                Coordinates
                of crosses (+) represent the performance from the left and right hemispheres in each reconstruction object.
                <strong>k</strong>
                Given similar example images, there is quite a difference in reconstruction objects from the left and right
                hemispheres.
                Their collaborated 3D scene exhibits an improvement in generation quality.
            </p> -->
        </div>
    </div>
</div>
    <hr class="divider" />

<div class="container" style="max-width: 768px;">
    <div class="row">
        <div class="col-md-12">
            <h4>Visual region predominates in comprehension</h4>
            <p>Visual regions in the brain show better performance than Medial Temporal Lobe (MTL) regions in various 3D processing
            methods like Inception, CLIP, EfficientNet, and Swav. The vision region, in particular, has a higher rate of objects
            with better scores in 3D Inception and 3D CLIP. Statistical significance is indicated by various p-values, showing
            differences between the MTL and other regions. There is only a slight positive correlation between the vision and MTL
            regions in object perception. While the MTL region is more focused on extracting semantic features from images, the
            vision region primarily deals with textures and silhouettes of objects.</p>

            <img src="assets/image/images2-1.png" style="width: 100%;">
            <!-- <p>
                <strong>a</strong> Visual regions exhibit better performance than MTL regions in 3D Inception, 3D CLIP, 3D
                EfficientNet and 3D
                Swav. <strong>b-c</strong> Vision region exhibits a higher proportion of objects with high 3D Inception and 3D CLIP
                scores.
                Crosses (+) represent the performance of each reconstruction object in each criterion. MTL vs all: 3D Inception:
                p=0.007,
                3D CLIP: p=0.05, 3D EfficientNet p=0.013 3D Swav p=0.017.* = p&lt;0.05, **=p&lt;0.01, ***=p&lt;0.001.
                <strong>d-g</strong> There is
                little positive correlation between vision and MTL region to perceive objects. Coordinates of crosses (+) represent
                the performance from vision and MTL in each reconstruction object. <strong>h</strong> MTL region tends to extract
                semantic
                features from the witnessed image, while the vision region concentrates on textures and silhouettes of the origin
                object.
            </p> -->

        </div>
    </div>
</div>


    <hr class="divider" />

<div class="container" style="max-width: 768px;">
    <div class="row">
        <div class="col-md-12">
            <h4>V1 Regions excel in features and silhouettes</h4>
            <p>V1 brain regions demonstrate superior performance in object perception, exhibiting higher scores in 3D Inception and 3D
            CLIP, but lower in 3D EfficientNet and 3D Swav, compared to other visual regions. They outperform V2, V3, and V4 regions
            in extracting and reconstructing objects. V2 and V3, as well as V2 and V4, show a strong positive correlation in the 3D
            CLIP correlation scatter plot. The V1 region is primarily involved in extracting and restoring features and silhouettes
            of images, whereas V2, V3, and V4 regions focus more on texture details.</p>
                    <img src="assets/image/images3-1.png" style="width: 100%;">

<!-- <p>
    <strong>a</strong> V1 regions show higher 3D Inception, 3D CLIP, and lower 3D EfficientNet and 3D Swav score,
    achieving better performance among all visual regions in object perception.
    <strong>b-e</strong> V1 Regions exhibit better performance than V2, V3 and V4 to extract and reconstruct objects.
    <strong>f</strong> V2 &amp; V3, V2 &amp; V4 shows a high positive correlation in the correlation scatter plot of 3D
    CLIP.
    <strong>g</strong> V1 region extracts and restores features and silhouettes of the given image, while V2, V3, and V4
    concentrate on a fraction of texture details.
</p> -->
        </div>
    </div>
</div>



    <hr class="divider" />
    
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h4>Low-Level and High-Level Embedding are both detrimental in visual processing</h4>
                <p>Integrating both low-level and high-level information processing enhances the human brain's ability to perceive objects.
                This is represented in boxplots showing median, 25th, and 75th percentiles among four metrics, with crosses indicating
                the scores of each image presented to participants. High-level embedding in functional Magnetic Resonance Imaging (fMRI)
                focuses on abstract semantic information, while low-level embedding deals with color and texture. The combination of
                these two types of embeddings in fMRI leads to improved object perception, encompassing both semantic and textural
                features.</p>
                <img src="assets/image/images4-1.png" style="width: 100%;">
<!--     
<p>
    <strong>a-d</strong> Integration of both Low-Level and High-Level is beneficial for human brains to better perceive
    objects. Boxplots exhibit the median, the 25th, and 75th percentiles as box edges among the four metrics. Crosses
    (+) represent the scores of each image with the category displayed to participants.
    <strong>e</strong> High-level embedding in fMRI concentrates on abstract semantic information, while low-level
    embedding in fMRI focuses on color and texture information. Their combination achieves the perception of objects in
    human brains with both semantic and texture features.
</p> -->

            </div>
        </div>
    </div>







<hr class="divider" />

<div class="container" style="max-width: 768px;">
    <div class="row">
        <div class="col-md-12">
            <h4>Semantic stage and UMAP projection both improve reconstruction quality</h4>
            <p>
                In various evaluation metrics and across all quantiles, the semantic stage in image processing significantly outperforms
                the perception stage, as evidenced by boxen plots covering a wide range of percentiles. This stage is characterized by a
                higher number of high scores in 3D Inception and 3D CLIP, alongside a shift towards lower scores in 3D EfficientNet and
                3D Swav. 3D objects processed in the semantic stage exhibit greater fidelity compared to those in the perception stage.
                The application of UMAP projection enhances reconstruction quality across all metrics and quantiles, leading to more
                scenes with high 3D Inception and 3D CLIP scores, while reducing 3D EfficientNet and 3D Swav scores. Additionally, UMAP
                projection contributes to improved textural stability in fMRI reconstructions.
            </p>
            <img src="assets/image/images5-1.png" style="width: 100%;">
<!-- <p>
    <strong>a</strong> The semantic stage outperforms the perception stage in all evaluation metrics in every quantile.
    Boxen plot shows 5&#37;, 15&#37;, 25&#37;, 50&#37;, 75&#37;, 85&#37;, and 95&#37; percentile.
    <strong>b</strong> The semantic stage exhibits a larger proportion of high 3D Inception and 3D CLIP scores and a
    left shift of 3D EfficientNet and 3D Swav scores.
    <strong>c</strong> The semantic stage 3D objects show higher fidelity than the perception stage.
    <strong>d</strong> UMAP projection improves reconstruction quality among all metrics in every quantile.
    <strong>e</strong> Employing UMAP projection achieves more scenes with high 3D Inception and 3D cLIP scores and
    enables smaller 3D EfficientNet and 3D Swav scores.
    <strong>f</strong> UMAP projection improves textural stability in fMRI reconstruction.
</p> -->

        </div>
    </div>
</div>






    </div>
    <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h3>More 3D scenes from fMRI</h3>
                <p>We also present more videos of 3D objects reconstructed through our Mind3D by decoding fMRI of participants, 
                    which offers a thorough overview of 3D details. 
                    It may takes a few seconds for our website to load videos.</p>
            </div>
        </div>
    </div>
        <!-- <div class="container" style="max-width: 768px;">
            <div class="row">
                <div class="col-md-12">
                    <p>
                        3D scenes                      </p>
                </div>
            </div>
        </div> -->
<div class="container" style="max-width: 768px; display: flex; justify-content: space-between;">

    <div class="half" style="width: 12%; text-align: center; margin-right: 1%;">
        <p>images</p>
    </div>
    <div class="half" style="width: 36%; text-align: center; margin-right: 2%;">
        <p>3D objects from fMRI</p>
    </div>
        <div class="half" style="width: 12%; text-align: center;margin-left: 1%;">
            <p>images</p>
        </div>
        <div class="half" style="width: 36%; text-align: center;">
            <p>3D objects from fMRI</p>
        </div>
</div>
<div class="container" style="max-width: 768px;">

<div class="row">


</div>
<div class="container" style="max-width: 768px;">
<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/369.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/369.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/360.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/360.mp4" type="video/mp4">
        </source>
    </video>
</div>


<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/290.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/290.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/145.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/145.mp4" type="video/mp4">
        </source>
    </video>
</div>







<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/110.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/110.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/112.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/112.mp4" type="video/mp4">
        </source>
    </video>
</div>

<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/325.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/325.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/42.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/42.mp4" type="video/mp4">
        </source>
    </video>
</div>


<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/46.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/46.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/55.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/55.mp4" type="video/mp4">
        </source>
    </video>
</div>

<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/90.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/90.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/289.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/289.mp4" type="video/mp4">
        </source>
    </video>
</div>


<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/41.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/41.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/22.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/22.mp4" type="video/mp4">
        </source>
    </video>
</div>


<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/11.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/11.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/44.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/44.mp4" type="video/mp4">
        </source>
    </video>
</div>


<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/10.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/10.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/85.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/85.mp4" type="video/mp4">
        </source>
    </video>
</div>


</body>

</html>
