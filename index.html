<!DOCTYPE html>
<html>

<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-XB3PR2Y1TQ"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-XB3PR2Y1TQ');
    </script>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <title>Brain3D</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/css/bootstrap.min.css">
    <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,500,600' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="/assets/css/Highlight-Clean.css">
    <link rel="stylesheet" href="/assets/css/styles.css">

    <link rel="apple-touch-icon" sizes="180x180" href="/assets/icon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/assets/icon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/assets/icon/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">

    <meta property="og:site_name" content="DreamFusion: Text-to-3D using 2D Diffusion" />
    <meta property="og:type" content="video.other" />
    <meta property="og:title" content="DreamFusion: Text-to-3D using 2D Diffusion" />
    <meta property="og:description" content="DreamFusion: Text-to-3D using 2D Diffusion, 2022." />
    <meta property="og:url" content="https://dreamfusion3d.github.io/" />
    <meta property="og:image" content="https://dreamfusion3d.github.io/assets/images/dreamfusion_samples.png" />

    <meta property="article:publisher" content="https://dreamfusion3d.github.io/" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="DreamFusion: Text-to-3D using 2D Diffusion" />
    <meta name="twitter:description" content="We combine neural rendering with a multi-modal text-to-2D image diffusion generative model to synthesize diverse 3D objects from text." />
    <meta name="twitter:url" content="https://dreamfusion3d.github.io/" />
    <meta name="twitter:image" content="https://dreamfusion3d.github.io/assets/images/dreamfusion_samples.png" />
    <!-- <meta name="twitter:site" content="" /> -->

    <script src="assets/js/video_comparison.js"></script>
    <script type="module" src="https://unpkg.com/@google/model-viewer@2.0.1/dist/model-viewer.min.js"></script>
</head>

<body>

    <div class="highlight-clean" style="padding-bottom: 10px;">
        <div class="container" style="max-width: 768px;">
            <h2 class="text-center">Brain3D: Generating 3D Objects from fMRI</h2>
        </div>
        <div class="container" style="max-width: 768px;">
            <h6 class="text-center">Yuankun Yang, Li Zhang(Corresponding Author), Ziyang Xie, Zhiyuan Yuan, Jianfeng Feng, Xiatian Zhu, Yu-Gang Jiang</h6>
        </div>
        <hr class="divider" />

        <div class="container" style="max-width: 768px;">
            <div style="text-align: center;">
                <img src="assets/image/figure1-1.png" style="width: 90%;">
            </div>
    
    </div>
    <hr class="divider" />

    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h3>Abstract</h3>
                <p>
                    Understanding the hidden mechanisms behind human's visual perception is a fundamental quest in neuroscience, underpins a wide variety of critical applications, e.g. clinical diagnosis. 
                    To that end, investigating into the neural responses of human mind activities,
                    such as functional Magnetic Resonance Imaging (fMRI),
                    has been a significant research vehicle.
                    However, analyzing fMRI signals is challenging, costly,
                    daunting, and demanding for professional training.
                    Despite remarkable progress in artificial intelligence (AI) based fMRI analysis, existing solutions are limited and far away from being clinically meaningful. 
                    In this context, we leap forward to demonstrate how AI can go beyond the current state of the art by decoding fMRI into visually plausible 3D visuals,
                    enabling automatic clinical analysis of fMRI data, even without healthcare professionals.
                    Innovationally, we reformulate the task of analyzing fMRI data as
                    a conditional 3D scene reconstruction problem.
                    We design a novel cross-modal 3D scene representation learning method, \ourmodel, that takes as input the fMRI data of a subject who was presented with a 2D object image,
                    and yields as output the corresponding 3D object visuals.
                    Importantly, we show that in simulated scenarios our AI agent captures the distinct functionalities of each region of human vision system
                    as well as their intricate interplay relationships, aligning remarkably with the established discoveries of neuroscience.
                    Non-expert diagnosis indicate that our model can successfully identify the disordered brain regions, such as V1, V2, V3, V4, and the medial temporal lobe (MTL) within the human visual system.
                    We also present results in cross-modal 3D visual construction setting, showcasing the perception quality of our 3D scene generation.
                </p>
            </div>
        </div>
    </div>


    <div class="container" style="max-width: 768px;">
        <div style="text-align: center;">
            <img src="assets/image/figure2-1.png" style="width: 95%;">
        </div>


    <hr class="divider" />
    
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h3>3D Reconstruction</h3>
                <p>
                    To test the effectiveness of Brain3D in 3D generation, we perform comprehensive comparisons with an existing 2D method.

                    From the fMRI data Brain3D extracts rich appearance, semantic and geometric information, presenting a high degree of consistency with the stimuli images.
                    Despite limited observation with the giraffe, skier and teddy bear in the three cases (see the last two rows), our bio-inspired model can process 3D details and comprehend their semantics beyond what is immediately visible in the 2D image, achieving finer semantic details than  MindEye<sup>1</sup>.
                    This result underscores the remarkable human's neural processing capability in constructing intricate 3D structures by interpreting and internalizing 3D geometric information from 2D visual stimuli.
                </p>
            </div>
        </div>
    </div>
<div class="container" style="max-width: 768px;">

<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
            <div class="half" style="width: 12%; text-align: center; margin-right: 1%;">
                <p>images</p>
            </div>
    <div class="half" style="width: 36%; text-align: center;; margin-right: 2%;">
            <p>3D objects from fMRI</p>
        </div>
        <div class="half" style="width: 12%; text-align: center; margin-left: 1%;">
            <p>images</p>
        </div>
        <div class="half" style="width: 36%; text-align: center;">
            <p>3D objects from fMRI</p>
        </div>
    <img src="assets/video/images_gt/209.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/209.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/323.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/323.mp4" type="video/mp4">
        </source>
    </video>
</div>



<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/79.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/79.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/39.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/39.mp4" type="video/mp4">
        </source>
    </video>
</div>




<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/9.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/9.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/222.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/222.mp4" type="video/mp4">
        </source>
    </video>
</div>




<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/147.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/147.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/177.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/177.mp4" type="video/mp4">
        </source>
    </video>
</div>

<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/340.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/340.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/77.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/77.mp4" type="video/mp4">
        </source>
    </video>
</div>

<!-- <div class="container" style="max-width: 768px;">
    <div style="text-align: center;">
        <img src="assets/image/figure3-1.png" style="width: 100%;">
    </div>
</div> -->

    <hr class="divider" />
<div class="container" style="max-width: 768px;">
    <div class="row">
        <div class="col-md-12">
            <h3>Results</h3>
            <h4>Enhanced visual quality through collaboration between the left and right hemispheres</h4>
            <p>We investigate whether our model presents biological consistency in terms of regional functionalities.
                We first examine the roles of the left and right brain hemispheres, as well as their collaboration during the 3D object reconstruction process. 
                Specifically, we observe that the two hemispheres make different holistic contributions to object perception, due to exhibiting distinct performances for specific objects. The left hemisphere tends to depict finer details and intricate structures in object visualization, while the right hemisphere better captures the overall shape and silhouette. These results align with previous discoveries that the left hemisphere is involved in detail-oriented tasks while the right hemisphere in more holistic tasks<sup>2</sup><sup>3</sup>.
            <img src="assets/image/figure4-1.png" style="width: 100%;">
        </div>
    </div>
</div>
    <hr class="divider" />

<div class="container" style="max-width: 768px;">
    <div class="row">
        <div class="col-md-12">
            <h4>Dominance of V1 visual regions  in feature and silhouette processing</h4>
            <p>We further investigate the functionalities of the various visual regions and the medial temporal lobe (MTL) region.
                Our research shows that the visual cortex exhibits higher visual decoding ability than MTL region. The significance level refers to the probability of error when rejecting the null hyothesis that visual cortex shares the similar performance as MTL region. Specifically, the visual cortex captures local fine-grained visual information such as the ``windows''  of an airplane and the ``motorcycle rider'', 
                while the MTL region captures holistic shapes like ``airplane skeleton'' and ``person''. This visualization 
                highlights higher-level 3D-shape-related concepts while foregoing pixel-level details. This finding provides a novel perspective on how the MTL region may contribute to the formation and recall of long-term memories, emphasizing its role in abstracting complex visual information.

                V1 region exhibits predominant ability in visual representation among various visual regions. 
                To further break down, V1 region plays a pivotal role in handling elementary visual information, including edges, features, and color.
                V2 and V3 regions play a role in synthesizing various features into complex visual forms,
                while V4 region focuses on basic color process at coarse level.
                However, our research brings to light a nuanced understanding of the interdependence within the visual cortex. Specifically, we demonstrate the reliance of the V2, V3, and V4 regions on the V1 region for constructing 3D vision. This is evident from the disrupted 3D geometries. This reliance likely stems from the fact that these regions process information initially received by V1<sup>4</sup>, indicating a foundational dependence on V1 for effective visual processing.
                These findings emphasize the collaborative and interactive roles of these brain regions in forming a comprehensive visual representation.
                This result is thus biologically consistent to great extent.
            </p>

            <img src="assets/image/figure5-1.png" style="width: 100%;">
        </div>
    </div>
</div>


    <hr class="divider" />

<div class="container" style="max-width: 768px;">
    <div class="row">
        <div class="col-md-12">
            <h4>Brain3D can diagnose regions with disorder</h4>
            <p>Motivated by the high biological consistency in terms of regional functions, we examine the usefulness of Brain3D in diagnosing disordered brain regions by designing a series of simulation based experiments.
                Notably, almost perfect diagnosis is achieved for the disorders with the V1 and MTL regions.
                V1 disorder tends to cause significant distortion to the output, consistent with the earlier finding about its critical role in processing basic visual information.
                Disorder in V2 region leads to changes in the detailed shape and motion of objects, e.g., orientation of the airplane and shape of the motorcycle.
                V3 region primarily affects the details and movements, e.g., the change from motorcycle to rider. Disorder in  V4 region might cause color shift and variation.
                Instead, MTL's disorder could be concerned with high-level semantics, e.g., increased ambiguity in object appearance.</p>
                    <img src="assets/image/figure6-1.png" style="width: 100%;">
        </div>
    </div>
</div>


    <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h3>More 3D scenes from fMRI</h3>
                <p>We also present more videos of 3D objects reconstructed through our Brain3D by decoding fMRI of participants, 
                    which offers a thorough overview of 3D details. 
                    It may takes a few seconds for our website to load videos.</p>
            </div>
        </div>
    </div>

<div class="container" style="max-width: 768px; display: flex; justify-content: space-between;">

    <div class="half" style="width: 12%; text-align: center; margin-right: 1%;">
        <p>images</p>
    </div>
    <div class="half" style="width: 36%; text-align: center; margin-right: 2%;">
        <p>3D objects from fMRI</p>
    </div>
        <div class="half" style="width: 12%; text-align: center;margin-left: 1%;">
            <p>images</p>
        </div>
        <div class="half" style="width: 36%; text-align: center;">
            <p>3D objects from fMRI</p>
        </div>
</div>
<div class="container" style="max-width: 768px;">

<div class="row">


</div>
<div class="container" style="max-width: 768px;">
<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/369.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/369.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/360.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/360.mp4" type="video/mp4">
        </source>
    </video>
</div>


<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/290.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/290.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/145.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/145.mp4" type="video/mp4">
        </source>
    </video>
</div>







<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/110.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/110.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/112.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/112.mp4" type="video/mp4">
        </source>
    </video>
</div>

<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/325.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/325.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/42.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/42.mp4" type="video/mp4">
        </source>
    </video>
</div>


<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/46.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/46.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/55.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/55.mp4" type="video/mp4">
        </source>
    </video>
</div>

<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/90.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/90.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/289.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/289.mp4" type="video/mp4">
        </source>
    </video>
</div>


<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/41.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/41.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/22.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/22.mp4" type="video/mp4">
        </source>
    </video>
</div>


<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/11.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/11.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/44.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/44.mp4" type="video/mp4">
        </source>
    </video>
</div>


<div class="row captioned_videos" style="display: flex; align-items: center; justify-content: space-around;">
    <img src="assets/video/images_gt/10.png" style="width: 12%; margin-right: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%; margin-right: 2%;">
        <source src="assets/video/video_fine_new/10.mp4" type="video/mp4">
        </source>
    </video>
    <img src="assets/video/images_gt/85.png" style="width: 12%; margin-left: 1%;">
    <video class="video lazy" loop playsinline autoplay muted style="width: 36%;">
        <source src="assets/video/video_fine_new/85.mp4" type="video/mp4">
        </source>
    </video>
</div>


<hr class="divider" />


<div class="container" style="max-width: 768px;">
    <h3>References</h3>
    <ol>
        <li>
            Scotti, P., Banerjee, A., Goode, J., Shabalin, S., Nguyen, A., Dempster, A.,  ...   Abraham, T. (2024). Reconstructing the mind's eye: fMRI-to-image with contrastive learning and diffusion priors. Advances in Neural Information Processing Systems, 36.      
        </li>
        <li>
            Iaccino, J. F. Left brain-right brain differences: Inquiries, evidence, and new approaches. Psychology Press. (2014). 
        </li>
        <li>
            Sun, T.,   Walsh, C. A. Molecular approaches to brain asymmetry and handedness. Nature Reviews Neuroscience, 7(8), 655-662. (2006).          
        </li>         
        <li>
            Hubel, D. H.,   Wiesel, T. N.  Brain mechanisms of vision. Scientific American, 241(3), 150-163. (1979).
        </li>                 
    </ol>
</div>

</body>

</html>
